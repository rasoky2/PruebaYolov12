import cv2
from ultralytics import YOLO
import os
import json
import numpy as np
from typing import Optional, Dict, Any, Tuple, Union
import time
from image import FilterManager
from arduino import ArduinoManager
from utils.logger import (
    info, success, warning, error,
    arduino_info,
    detection_info, detection_error,
    camera_log, camera_ok, camera_error,
    filter_info_detailed, performance_info, yolo_info,
    separator, title
)

# Variables globales para Arduino
arduino_manager = None

# Variable global para dispositivo de procesamiento
device = "cpu"  # Por defecto CPU

def init_arduino_manager():
    """Inicializar el gestor de Arduino"""
    global arduino_manager
    arduino_manager = ArduinoManager()
    return arduino_manager

def load_camera_config() -> Optional[Dict[str, Any]]:
    """Cargar configuraci√≥n de c√°maras desde JSON"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(script_dir, "camera_config.json")
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        return config
    except FileNotFoundError:
        warning("Archivo camera_config.json no encontrado. Usando configuraci√≥n por defecto.")
        return None
    except json.JSONDecodeError:
        error("Error al leer camera_config.json. Usando configuraci√≥n por defecto.")
        return None

def get_camera_name(cam_id: int, config: Optional[Dict[str, Any]]) -> str:
    """Obtener nombre personalizado de la c√°mara"""
    if config and "cameras" in config and str(cam_id) in config["cameras"]:
        return config["cameras"][str(cam_id)]["name"]
    return f"Dispositivo {cam_id}"

def get_camera_description(cam_id: int, config: Optional[Dict[str, Any]]) -> str:
    """Obtener descripci√≥n de la c√°mara"""
    if config and "cameras" in config and str(cam_id) in config["cameras"]:
        return config["cameras"][str(cam_id)].get("description", "")
    return ""

def is_favorite_camera(cam_id: int, config: Optional[Dict[str, Any]]) -> bool:
    """Verificar si la c√°mara es favorita"""
    if config and "cameras" in config and str(cam_id) in config["cameras"]:
        return config["cameras"][str(cam_id)].get("is_favorite", False)
    return False

def get_favorite_camera(config: Optional[Dict[str, Any]]) -> Optional[int]:
    """Obtener la c√°mara favorita"""
    if config and "cameras" in config:
        for cam_id, cam_info in config["cameras"].items():
            if cam_info.get("is_favorite", False):
                return int(cam_id)
    return None

def assign_color(chestnut_type: str) -> Tuple[int, int, int]:
    """Asignar colores espec√≠ficos para casta√±as"""
    color_map = {
        'sana': (0, 255, 0),        # Verde - Casta√±a sana
        'contaminada': (0, 0, 255),  # Rojo - Casta√±a contaminada
        'casta√±a': (255, 165, 0),    # Naranja - Casta√±a general
    }
    return color_map.get(chestnut_type, (255, 255, 255))  # Blanco por defecto

# Funciones de filtros movidas a image/filters.py

def detect_green_fluorescence(crop_img: np.ndarray) -> float:
    """Detectar fluorescencia verde brillante espec√≠fica de metabolitos f√∫ngicos"""
    if crop_img is None or crop_img.size == 0:
        return 0.0
    
    # Convertir a HSV para an√°lisis de color
    hsv = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)
    
    # Definir rango de verde brillante fluorescente (verde ne√≥n)
    # H: 60-85 (verde), S: 200-255 (muy saturado), V: 200-255 (muy brillante)
    lower_green_fluor = np.array([60, 200, 200])
    upper_green_fluor = np.array([85, 255, 255])
    
    # Crear m√°scara para fluorescencia verde
    green_mask = cv2.inRange(hsv, lower_green_fluor, upper_green_fluor)
    
    # Calcular porcentaje de p√≠xeles con fluorescencia verde
    total_pixels = crop_img.shape[0] * crop_img.shape[1]
    fluorescent_pixels = np.sum(green_mask > 0)
    fluorescence_ratio = fluorescent_pixels / total_pixels
    
    # Tambi√©n detectar verde muy brillante en RGB (para casos extremos)
    b, g, r = cv2.split(crop_img)
    
    # Buscar p√≠xeles donde G >> R y G >> B (verde dominante y brillante)
    green_dominant = (g > r * 1.5) & (g > b * 1.5) & (g > 200)
    bright_green_ratio = np.sum(green_dominant) / total_pixels
    
    # Combinar ambas detecciones
    total_fluorescence = fluorescence_ratio + bright_green_ratio
    
    return min(total_fluorescence, 1.0)  # Cap a 1.0

def analyze_chestnut_quality(crop_img: Optional[np.ndarray]) -> str:
    """Analizar calidad de casta√±a usando an√°lisis HSV, textura y fluorescencia verde"""
    if crop_img is None or crop_img.size == 0:
        return 'sana'  # Por defecto si no se puede analizar
    
    # NUEVA DETECCI√ìN: Fluorescencia verde (contaminaci√≥n f√∫ngica)
    fluorescence_score = detect_green_fluorescence(crop_img)
    
    # Si hay fluorescencia verde significativa, es contaminada
    if fluorescence_score > 0.05:  # M√°s del 5% de fluorescencia verde
        return 'contaminada'
    
    # Convertir a HSV para an√°lisis de color tradicional
    hsv = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)
    _, s, v = cv2.split(hsv)  # Usar _ para variable no usada
    
    # Calcular estad√≠sticas de color
    mean_s = np.mean(s)
    mean_v = np.mean(v)
    std_v = np.std(v)  # Desviaci√≥n est√°ndar del brillo
    
    # An√°lisis de textura simple (detecci√≥n de bordes)
    gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])
    
    # Heur√≠stica para clasificar (ajustable seg√∫n tus im√°genes)
    # Casta√±as contaminadas suelen tener:
    # - Menor brillo (valores V bajos)
    # - Menor saturaci√≥n (colores m√°s gris√°ceos)
    # - M√°s bordes (manchas, moho, irregularidades)
    # - Fluorescencia verde (ya detectada arriba)
    
    contamination_score = 0
    
    # Factor 1: Brillo bajo (posible moho o manchas oscuras)
    if mean_v < 70:
        contamination_score += 2
    elif mean_v < 100:
        contamination_score += 1
    
    # Factor 2: Saturaci√≥n baja (colores apagados)
    if mean_s < 40:
        contamination_score += 2
    elif mean_s < 60:
        contamination_score += 1
    
    # Factor 3: Mucha variaci√≥n en brillo (manchas)
    if std_v > 35:
        contamination_score += 1
    
    # Factor 4: Alta densidad de bordes (textura irregular)
    if edge_density > 0.15:
        contamination_score += 1
    
    # Factor 5: Fluorescencia verde (ya considerado arriba, pero agregar peso)
    contamination_score += int(fluorescence_score * 10)  # Peso alto para fluorescencia
    
    # Clasificar basado en puntuaci√≥n
    return 'contaminada' if contamination_score >= 1 else 'sana'

def analyze_chestnut_quality_dual(crop_img: Optional[np.ndarray], filter_manager: FilterManager = None) -> str:
    """An√°lisis dual: RGB normal + simulaci√≥n UV + detecci√≥n de fluorescencia verde para m√°xima precisi√≥n"""
    if crop_img is None or crop_img.size == 0:
        return 'sana'
    
    # An√°lisis RGB normal (incluye detecci√≥n de fluorescencia verde)
    rgb_result = analyze_chestnut_quality(crop_img)
    
    # An√°lisis espec√≠fico para fluorescencia UV-A si est√° disponible
    uv_fluorescence_result = 'sana'
    if filter_manager:
        try:
            # Aplicar filtro UV-A fluorescencia si est√° disponible
            uv_img, _, _ = filter_manager.apply_filter(crop_img, "uv_fluorescence")
            if uv_img is not None:
                # Detectar fluorescencia verde espec√≠ficamente en imagen UV
                fluorescence_score = detect_green_fluorescence(uv_img)
                if fluorescence_score > 0.03:  # Umbral m√°s bajo para UV (3%)
                    uv_fluorescence_result = 'contaminada'
                    detection_info(f"Fluorescencia UV detectada: {fluorescence_score:.3f}")
        except Exception:
            # Fallback si no hay filtro UV disponible
            pass
    
    # An√°lisis con filtro de grietas usando FilterManager
    crack_result = 'sana'
    if filter_manager:
        try:
            crack_img, _, _ = filter_manager.apply_filter(crop_img, "crack")
            crack_result = analyze_chestnut_quality(crack_img)
        except Exception:
            crack_result = rgb_result
    
    # L√≥gica de decisi√≥n dual mejorada
    # Si cualquiera de los an√°lisis detecta contaminaci√≥n, marcar como contaminada
    final_result = 'contaminada' if (
        rgb_result == 'contaminada' or 
        crack_result == 'contaminada' or 
        uv_fluorescence_result == 'contaminada'
    ) else 'sana'
    
    # Log detallado si hay fluorescencia detectada
    if final_result == 'contaminada':
        fluorescence_score = detect_green_fluorescence(crop_img)
        if fluorescence_score > 0.05:
            detection_info(f"CONTAMINACI√ìN DETECTADA - Fluorescencia verde: {fluorescence_score:.3f}")
    
    return final_result

def classify_chestnut(label: str, confidence: float, crop_img: Optional[np.ndarray] = None, filter_manager: FilterManager = None) -> Optional[str]:
    """Clasificar casta√±as en sanas o contaminadas usando YOLO + an√°lisis RGB"""
    label_lower = label.lower()
    
    # Clases que detectan casta√±as (similares por forma) - Actualizado con an√°lisis YOLO12n
    chestnut_classes = ['sports ball', 'apple', 'orange', 'donut', 'bowl']
    
    # Verificar si es una clase que puede ser casta√±a
    if label_lower not in chestnut_classes:
        return None  # No es una casta√±a
    
    # Si tenemos la imagen recortada, usar an√°lisis dual RGB + UV
    if crop_img is not None:
        return analyze_chestnut_quality_dual(crop_img, filter_manager)
    
    # Configuraci√≥n de clasificaci√≥n por clase y confianza
    classification_rules = {
        'sports ball': {'sana': 0.6, 'contaminada': 0.4},
        'apple': {'sana': 0.7, 'contaminada': 0.5},
        'orange': {'sana': 0.4, 'contaminada': 0.6},
        'donut': {'sana': 0.8, 'contaminada': 0.6},
        'bowl': {'sana': 0.8, 'contaminada': 0.6}
    }
    
    # Aplicar reglas de clasificaci√≥n
    rules = classification_rules.get(label_lower, {})
    if not rules:
        return None
    
    if confidence >= rules.get('sana', 0):
        return 'sana'
    elif confidence >= rules.get('contaminada', 0):
        return 'contaminada'
    
    return None  # No clasificar si confianza muy baja

def switch_camera(new_camera_id: int, available_cameras: list, current_camera_id: int, camera_live) -> Tuple[int, Any]:
    """Cambiar a una nueva c√°mara"""
    if new_camera_id in available_cameras and new_camera_id != current_camera_id:
        # Cerrar c√°mara actual
        camera_live.release()
        
        # Abrir nueva c√°mara
        new_camera = cv2.VideoCapture(new_camera_id)
        if new_camera.isOpened():
            new_camera.set(3, 1280)  # Ancho
            new_camera.set(4, 720)   # Alto
            camera_ok(f"Cambiado a c√°mara {new_camera_id}")
            return new_camera_id, new_camera
        else:
            camera_error(f"No se pudo abrir c√°mara {new_camera_id}")
            # Restaurar c√°mara anterior
            old_camera = cv2.VideoCapture(current_camera_id)
            old_camera.set(3, 1280)
            old_camera.set(4, 720)
            return current_camera_id, old_camera
    else:
        camera_error(f"C√°mara {new_camera_id} no disponible o ya seleccionada")
        return current_camera_id, camera_live

def create_dual_view(normal_img: np.ndarray, model: YOLO, conf: float = 0.5, filter_type: str = "nir", filter_manager: FilterManager = None) -> Tuple[np.ndarray, int, int, int]:
    """Crear vista dual: c√°mara normal + filtro especializado con detecciones"""
    # Usar FilterManager (requerido)
    if filter_manager:
        # Manejar pipeline especial
        if filter_type == "pipeline":
            filtered_processed, contamination_scores, pipeline_desc = filter_manager.apply_fungal_contamination_pipeline(normal_img.copy())
            filter_name = "PIPELINE COMPLETO"
            filter_desc = f"Score: {contamination_scores.get('total', 0.0):.2f}"
            
            # Mostrar reporte detallado cada 60 frames
            if hasattr(create_dual_view, 'frame_count'):
                create_dual_view.frame_count += 1
            else:
                create_dual_view.frame_count = 1
                
            if create_dual_view.frame_count % 60 == 0:  # Cada 2 segundos aprox
                filter_info_detailed(pipeline_desc)
        else:
            filtered_processed, filter_name, filter_desc = filter_manager.apply_filter(normal_img.copy(), filter_type)
    else:
        # Error si no hay FilterManager
        error("FilterManager es requerido para create_dual_view")
        return normal_img, 0, 0, 0
    
    # ‚ö° OPTIMIZACI√ìN CR√çTICA: Solo una predicci√≥n YOLO (mejora 2x velocidad)
    # Usar solo la imagen normal para detecci√≥n, aplicar filtro solo para visualizaci√≥n
    normal_result = model.predict(normal_img, conf=conf, verbose=False, device=device)
    # filtered_result = model.predict(filtered_processed, conf=conf, verbose=False, device=device if 'device' in globals() else 'cpu')  # ELIMINADO
    
    # Dibujar detecciones en imagen normal
    normal_with_detections = normal_img.copy()
    filtered_with_detections = filtered_processed.copy()
    
    total_castanas = 0
    sana_count = 0
    contaminada_count = 0
    
    # Procesar detecciones en imagen normal
    for result in normal_result:
        if result.boxes is not None:
            for box in result.boxes:
                label = f"{result.names[int(box.cls[0])]}"
                score = box.conf.item()
                
                # Recortar la regi√≥n detectada para an√°lisis dual
                x1, y1, x2, y2 = int(box.xyxy[0][0]), int(box.xyxy[0][1]), int(box.xyxy[0][2]), int(box.xyxy[0][3])
                
                # Asegurar que las coordenadas est√°n dentro de la imagen
                x1 = max(0, x1)
                y1 = max(0, y1)
                x2 = min(normal_img.shape[1], x2)
                y2 = min(normal_img.shape[0], y2)
                
                if x2 > x1 and y2 > y1:
                    # Recortar imagen de la casta√±a para an√°lisis dual
                    crop_img = normal_img[y1:y2, x1:x2]
                    
                    # Clasificar casta√±a usando an√°lisis dual
                    chestnut_type = classify_chestnut(label, score, crop_img, filter_manager)
                    
                    if chestnut_type is not None:
                        total_castanas += 1
                        if chestnut_type == 'sana':
                            sana_count += 1
                        elif chestnut_type == 'contaminada':
                            contaminada_count += 1
                        
                        color = assign_color(chestnut_type)
                        
                        # Dibujar en imagen normal
                        cv2.rectangle(normal_with_detections, (x1, y1), (x2, y2), color, 2)
                        label_text = f"{chestnut_type.upper()}: {score:.2f}"
                        cv2.putText(normal_with_detections, label_text, (x1, y1-10), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
                        
                        # Dibujar en imagen filtrada (mismo rect√°ngulo, sin clasificaci√≥n adicional)
                        cv2.rectangle(filtered_with_detections, (x1, y1), (x2, y2), color, 2)
                        cv2.putText(filtered_with_detections, label_text, (x1, y1-10), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
    
    # Enviar se√±al al Arduino basada en el estado general del frame
    if arduino_manager and arduino_manager.enabled:
        arduino_manager.send_detection_signals(total_castanas, contaminada_count)
    
    # Crear vista dual lado a lado
    height, width = normal_with_detections.shape[:2]
    dual_view = np.zeros((height, width * 2, 3), dtype=np.uint8)
    
    # Colocar im√°genes lado a lado
    dual_view[:, :width] = normal_with_detections
    dual_view[:, width:] = filtered_with_detections
    
    # Agregar t√≠tulos con colores distintivos
    cv2.putText(dual_view, "CAMARA NORMAL", (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)  # Verde
    cv2.putText(dual_view, filter_name, (width + 10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 3)  # Magenta
    
    # Agregar subt√≠tulos explicativos
    cv2.putText(dual_view, "(RGB Natural)", (10, 60), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)
    cv2.putText(dual_view, filter_desc, (width + 10, 60), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)
    
    # L√≠nea divisoria
    cv2.line(dual_view, (width, 0), (width, height), (255, 255, 255), 2)
    
    return dual_view, total_castanas, sana_count, contaminada_count

def predict(model: YOLO, img: np.ndarray, conf: float = 0.5, filter_manager: FilterManager = None) -> Tuple[np.ndarray, Any, int, int, int]:
    """Realizar predicci√≥n y visualizar SOLO detecciones de casta√±as (sanas y contaminadas)"""
    
    sana_count = 0
    contaminada_count = 0
    total_castanas = 0
    
    # Realizar predicci√≥n
    results = model.predict(img, conf=conf)
    
    # Procesar resultados - SOLO casta√±as
    for result in results:
        if result.boxes is not None:
            for box in result.boxes:
                label = f"{result.names[int(box.cls[0])]}"
                score = box.conf.item()
                
                # Recortar la regi√≥n detectada para an√°lisis RGB
                x1, y1, x2, y2 = int(box.xyxy[0][0]), int(box.xyxy[0][1]), int(box.xyxy[0][2]), int(box.xyxy[0][3])
                
                # Asegurar que las coordenadas est√°n dentro de la imagen
                x1 = max(0, x1)
                y1 = max(0, y1)
                x2 = min(img.shape[1], x2)
                y2 = min(img.shape[0], y2)
                
                # Recortar imagen para an√°lisis
                crop_img = img[y1:y2, x1:x2] if y2 > y1 and x2 > x1 else None
                
                # Clasificar si es casta√±a y de qu√© tipo usando an√°lisis RGB
                chestnut_type = classify_chestnut(label, score, crop_img, filter_manager)
                
                if chestnut_type is not None:  # Solo procesar casta√±as
                    total_castanas += 1
                    
                    # Contar por tipo
                    if chestnut_type == 'sana':
                        sana_count += 1
                        emoji = "[OK]"
                    elif chestnut_type == 'contaminada':
                        contaminada_count += 1
                        emoji = "[ERROR]"
                    else:
                        emoji = "[CHESTNUT]"
                    
                    # Obtener color seg√∫n el tipo
                    color = assign_color(chestnut_type)
                    
                    # Dibujar rect√°ngulo (m√°s grueso para destacar)
                    cv2.rectangle(img, (x1, y1), (x2, y2), color=color, thickness=6)
                    
                    # Mostrar etiqueta con informaci√≥n
                    font = cv2.FONT_HERSHEY_SIMPLEX
                    label_text = f"{emoji} Casta√±a {chestnut_type} ({score:.2f})"
                    
                    cv2.putText(img, label_text, (x1, y1 - 10), font, 0.8, color=color, thickness=2)
    
    # Mostrar informaci√≥n SOLO de casta√±as en la imagen
    info_text = f"Casta√±as: {total_castanas} | Sanas: {sana_count} | Contaminadas: {contaminada_count}"
    cv2.putText(img, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    cv2.putText(img, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)
    
    return img, results, total_castanas, sana_count, contaminada_count

def main_func():
    """Funci√≥n principal para detecci√≥n de casta√±as sanas y contaminadas"""
    title("Detector de Casta√±as - An√°lisis √ìptico Avanzado + Arduino")
    detection_info("Verde: Casta√±as SANAS (an√°lisis HSV + textura + filtros √≥pticos)")
    detection_error("Rojo: Casta√±as CONTAMINADAS (grietas, moho, hongos detectados)")
    detection_error("NUEVO: Detecci√≥n autom√°tica de fluorescencia verde ne√≥n (metabolitos f√∫ngicos)")
    yolo_info("M√©todo: YOLO12n detecta ‚Üí An√°lisis dual RGB + filtros √≥pticos especializados clasifica")
    info("Filtros √ìpticos: Grietas (polarizaci√≥n), UV-A (fluorescencia verde), NIR (humedad), Hongos")
    info("Detecci√≥n Fluorescencia: Verde ne√≥n = Contaminaci√≥n f√∫ngica (umbral >5% p√≠xeles)")
    arduino_info("Arduino: Activa servo cuando detecta contaminaci√≥n")
    
    # Cargar configuraci√≥n de c√°maras
    camera_config = load_camera_config()
    
    # Inicializar sistema de filtros
    filter_manager = FilterManager()
    filter_info_detailed(f"Sistema de filtros inicializado (GPU: {'‚úÖ' if filter_manager.cuda_available else '‚ùå'})")
    
    # Cargar modelo YOLO12 preentrenado
    script_dir = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.join(script_dir, "core", "yolo12n.pt")
    
    yolo_info(f"Cargando modelo YOLO12n: {model_path}")
    
    try:
        # Verificar disponibilidad de GPU
        import torch
        global device  # Declarar global al inicio
        info("Verificando GPU...")
        info(f"   - PyTorch versi√≥n: {torch.__version__}")
        info(f"   - CUDA disponible: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            info(f"   - GPU detectada: {torch.cuda.get_device_name(0)}")
            info(f"   - Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
            device = "cuda"
            performance_info("Usando GPU para YOLO")
        else:
            warning("GPU no disponible, usando CPU")
            device = "cpu"
        
        # Cargar modelo con dispositivo espec√≠fico
        model = YOLO(model_path)
        
        # Mover modelo a GPU si est√° disponible
        if torch.cuda.is_available():
            model.to(device)
            yolo_info("Modelo YOLO12n cargado en GPU exitosamente")
        else:
            yolo_info("Modelo YOLO12n cargado en CPU exitosamente")
            
    except Exception as e:
        error(f"Error cargando modelo YOLO12: {e}")
        info("Intentando con modelo YOLOv8 como respaldo...")
        try:
            backup_path = os.path.join(script_dir, "core", "yolov8n.pt")
            model = YOLO(backup_path)
            
            # Mover modelo de respaldo a GPU si est√° disponible
            if torch.cuda.is_available():
                model.to(device)
                yolo_info("Modelo YOLOv8 de respaldo cargado en GPU exitosamente")
            else:
                yolo_info("Modelo YOLOv8 de respaldo cargado en CPU exitosamente")
        except Exception as e2:
            error(f"Error cargando modelo de respaldo: {e2}")
            return
    
    # Mostrar informaci√≥n del modelo
    info("Informaci√≥n del modelo:")
    info(f"   - Dispositivo: {device.upper()}")
    info(f"   - Clases disponibles: {list(model.names.values())}")
    info(f"   - N√∫mero de clases: {len(model.names)}")
    
    # Mostrar rendimiento esperado
    if device == "cuda":
        performance_info("Rendimiento: GPU acelerado - Detecci√≥n ultra-r√°pida")
    else:
        warning("Rendimiento: CPU - Detecci√≥n m√°s lenta")
    
    # Inicializar gestor de Arduino
    global arduino_manager
    arduino_manager = init_arduino_manager()
    
    # Configuraci√≥n interactiva de Arduino
    arduino_manager.interactive_setup()
    
    # Detectar c√°maras disponibles con informaci√≥n detallada
    available_cameras = []
    camera_info = {}
    
    info("Detectando c√°maras disponibles...")
    
    for i in range(5):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            # Obtener informaci√≥n de la c√°mara
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            
            # Obtener nombre personalizado desde configuraci√≥n
            device_name = get_camera_name(i, camera_config)
            device_description = get_camera_description(i, camera_config)
            is_favorite = is_favorite_camera(i, camera_config)
            
            camera_info[i] = {
                'name': device_name,
                'description': device_description,
                'resolution': f"{width}x{height}",
                'fps': fps,
                'width': width,
                'height': height,
                'is_favorite': is_favorite
            }
            
            available_cameras.append(i)
            cap.release()
    
    if not available_cameras:
        camera_error("No se encontraron c√°maras disponibles")
        return
    
    # Mostrar informaci√≥n detallada de las c√°maras
    info(f"\nC√°maras disponibles ({len(available_cameras)} encontradas):")
    separator("-", 70, "CYAN")
    
    favorite_cam_id = None
    for cam_id in available_cameras:
        cam_info = camera_info[cam_id]
        favorite_marker = " (FAVORITA)" if cam_info['is_favorite'] else ""
        camera_log(f"C√°mara {cam_id}: {cam_info['name']}{favorite_marker}")
        
        if cam_info['description']:
            info(f"      {cam_info['description']}")
        
        info(f"      Resoluci√≥n: {cam_info['resolution']} | FPS: {cam_info['fps']:.1f}")
        
        if cam_info['is_favorite']:
            favorite_cam_id = cam_id
        print()
    separator("-", 70, "CYAN")
    
    # Seleccionar c√°mara (siempre preguntar al usuario)
    camera_id = None
    
    while camera_id is None:
        try:
            info(f"\nSelecci√≥n de c√°mara:")
            info(f"   C√°maras disponibles: {available_cameras}")
            
            # Mostrar res√∫men r√°pido de cada c√°mara
            for cam_id in available_cameras:
                cam_info = camera_info[cam_id]
                favorite_marker = " (FAVORITA)" if cam_info['is_favorite'] else ""
                info(f"   {cam_id}: {cam_info['name']}{favorite_marker} - {cam_info['resolution']} @ {cam_info['fps']:.0f}fps")
            
            # Sugerir c√°mara favorita o por defecto
            default_cam = favorite_cam_id if favorite_cam_id else available_cameras[0]
            default_text = f"c√°mara favorita ({default_cam})" if favorite_cam_id else f"c√°mara {default_cam}"
            
            camera_choice = input(f"\nSelecciona una c√°mara ({available_cameras[0]}-{available_cameras[-1]}) o presiona Enter para usar la {default_text}: ").strip()
            
            if camera_choice == "":
                # Usar c√°mara favorita o por defecto 
                camera_id = default_cam
                cam_info = camera_info[camera_id]
                favorite_text = " (FAVORITA)" if cam_info['is_favorite'] else ""
                camera_ok(f"Usando {default_text}: {cam_info['name']} ({cam_info['resolution']} @ {cam_info['fps']:.0f}fps){favorite_text}")
            else:
                camera_id = int(camera_choice)
                if camera_id in available_cameras:
                    cam_info = camera_info[camera_id]
                    favorite_text = " (FAVORITA)" if cam_info['is_favorite'] else ""
                    camera_ok(f"C√°mara {camera_id} seleccionada: {cam_info['name']} ({cam_info['resolution']} @ {cam_info['fps']:.0f}fps){favorite_text}")
                else:
                    camera_error(f"C√°mara {camera_id} no disponible. Intenta con una de estas: {available_cameras}")
                    camera_id = None  # Reiniciar el bucle
                    
        except ValueError:
            error("Por favor ingresa un n√∫mero v√°lido")
            camera_id = None  # Reiniciar el bucle
        except (EOFError, KeyboardInterrupt):
            warning("\nSelecci√≥n cancelada. Usando c√°mara favorita...")
            camera_id = default_cam
            cam_info = camera_info[camera_id]
            favorite_text = " (FAVORITA)" if cam_info['is_favorite'] else ""
            camera_ok(f"Usando c√°mara por defecto: {cam_info['name']} ({cam_info['resolution']} @ {cam_info['fps']:.0f}fps){favorite_text}")
    
    camera_live = cv2.VideoCapture(camera_id)
    
    if not camera_live.isOpened():
        camera_error(f"No se pudo abrir la c√°mara {camera_id}")
        return
    
    # Usar la resoluci√≥n nativa de la c√°mara seleccionada
    selected_info = camera_info[camera_id]
    native_width = selected_info['width']
    native_height = selected_info['height']
    native_fps = selected_info['fps']
    
    # Intentar configurar la resoluci√≥n nativa
    camera_live.set(cv2.CAP_PROP_FRAME_WIDTH, native_width)
    camera_live.set(cv2.CAP_PROP_FRAME_HEIGHT, native_height)
    camera_live.set(cv2.CAP_PROP_FPS, native_fps)
    
    # Verificar la resoluci√≥n configurada
    actual_width = int(camera_live.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_height = int(camera_live.get(cv2.CAP_PROP_FRAME_HEIGHT))
    actual_fps = camera_live.get(cv2.CAP_PROP_FPS)
    
    camera_ok("C√°mara configurada:")
    info(f"   Dispositivo: {selected_info['name']}")
    if selected_info['description']:
        info(f"   Descripci√≥n: {selected_info['description']}")
    info(f"   Resoluci√≥n: {actual_width}x{actual_height}")
    info(f"   FPS: {actual_fps:.1f}")
    if selected_info['is_favorite']:
        info(f"   Estado: C√ÅMARA FAVORITA")
    
    info("\nControles:")
    info("   - ESC: Salir")
    info("   - 'c': Cambiar confianza")
    info("   - 's': Guardar captura")
    info("   - 'i': Mostrar informaci√≥n del modelo")
    info("   - 'm': Cambiar c√°mara")
    info("   - 'f': Cambiar filtro (men√∫ completo)")
    info("   - 'F': Mostrar informaci√≥n de filtros favoritos")
    info("   - 'o': Optimizaci√≥n manual (limpiar memoria)")
    # Mostrar teclas r√°pidas desde configuraci√≥n
    quick_keys_help = filter_manager.get_quick_keys_help()
    info(f"\n{quick_keys_help}")
    
    frame_count = 0
    total_sanas = 0
    total_contaminadas = 0
    frames_con_castanas = 0
    confidence = 0.5
    current_filter = filter_manager.default_filter  # Filtro por defecto desde configuraci√≥n
    
    # Variables para medir rendimiento
    fps_counter = 0
    fps_start_time = time.time()
    current_fps = 0
    
    # Variables para optimizaci√≥n de memoria
    frame_skip_counter = 0
    frame_skip_interval = 2  # Procesar 1 de cada 2 frames para reducir carga
    memory_cleanup_interval = 300  # Limpiar memoria cada 300 frames (~10 segundos a 30fps)
    frame_count_memory = 0
    
    # Variables para control de carga del sistema
    processing_times = []
    max_processing_time = 0.05  # M√°ximo 50ms por frame (20 FPS m√≠nimo)
    
    while camera_live.isOpened():
        read, frame = camera_live.read()
        if not read:
            continue
        
        frame_count += 1
        fps_counter += 1
        frame_count_memory += 1
        frame_skip_counter += 1
        
        # Medir tiempo de procesamiento
        frame_start_time = time.time()
        
        # OPTIMIZACI√ìN 1: Saltar frames para reducir carga del sistema
        if frame_skip_counter < frame_skip_interval:
            # Mostrar frame anterior sin procesar
            if 'dual_view' in locals():
                cv2.imshow('[CHESTNUT] Vista Dual: Normal + Filtros √ìpticos Avanzados', dual_view)
                key = cv2.waitKey(1) & 0xFF
                if key == 27:  # ESC
                    break
            continue
        
        frame_skip_counter = 0  # Resetear contador
        
        # OPTIMIZACI√ìN 2: Limpieza peri√≥dica de memoria
        if frame_count_memory >= memory_cleanup_interval:
            import gc
            gc.collect()  # Forzar garbage collection
            if device == "cuda":
                import torch
                torch.cuda.empty_cache()  # Limpiar cache de GPU
            frame_count_memory = 0
            performance_info(f"Memoria limpiada en frame {frame_count}")
        
        # Crear vista dual: c√°mara normal + filtro especializado
        dual_view, total_castanas, sanas, contaminadas = create_dual_view(frame, model, conf=confidence, filter_type=current_filter, filter_manager=filter_manager)
        
        # OPTIMIZACI√ìN 3: Medir tiempo de procesamiento y ajustar din√°micamente
        frame_processing_time = time.time() - frame_start_time
        processing_times.append(frame_processing_time)
        
        # Mantener solo los √∫ltimos 30 tiempos de procesamiento
        if len(processing_times) > 30:
            processing_times.pop(0)
        
        # Calcular tiempo promedio de procesamiento
        avg_processing_time = sum(processing_times) / len(processing_times) if processing_times else 0
        
        # Ajustar din√°micamente el intervalo de salto de frames si el sistema est√° sobrecargado
        if avg_processing_time > max_processing_time:
            frame_skip_interval = min(frame_skip_interval + 1, 4)  # M√°ximo salto de 3 frames
            if frame_count % 60 == 0:  # Cada 2 segundos aproximadamente
                performance_info(f"Sistema sobrecargado ({avg_processing_time:.3f}s), aumentando intervalo a {frame_skip_interval}")
        elif avg_processing_time < max_processing_time * 0.5 and frame_skip_interval > 1:
            frame_skip_interval = max(frame_skip_interval - 1, 1)  # Reducir intervalo si el sistema est√° bien
            if frame_count % 60 == 0:
                performance_info(f"Sistema estable ({avg_processing_time:.3f}s), reduciendo intervalo a {frame_skip_interval}")
        
        # Calcular FPS cada 30 frames
        if fps_counter >= 30:
            current_time = time.time()
            elapsed_time = current_time - fps_start_time
            current_fps = fps_counter / elapsed_time
            fps_counter = 0
            fps_start_time = current_time
        
        # Acumular estad√≠sticas
        total_sanas += sanas
        total_contaminadas += contaminadas
        if total_castanas > 0:
            frames_con_castanas += 1
        
        # Mostrar informaci√≥n adicional con FPS y rendimiento
        fps_text = f"FPS: {current_fps:.1f}" if current_fps > 0 else "FPS: Calculando..."
        processing_text = f"Proc: {avg_processing_time:.3f}s | Skip: {frame_skip_interval}"
        status_text = f"Frame: {frame_count} | {fps_text} | {processing_text} | Confianza: {confidence:.2f}"
        stats_text = f"Sanas: {total_sanas} | Contaminadas: {total_contaminadas}"
        camera_text = f"C√°mara: {camera_id} | Filtro: {current_filter.upper()} | Teclas: 1-8 para filtros r√°pidos"
        
        # Informaci√≥n de Arduino
        if arduino_manager and arduino_manager.enabled:
            status_info = arduino_manager.get_status_info()
            arduino_status = "[ARDUINO] Arduino: CONECTADO"
            signal_color = status_info['signal_color']
            arduino_text = f"√öltima se√±al: {status_info['last_signal']}" if status_info['last_signal'] else "Esperando detecci√≥n..."
            behavior_text = status_info['behavior_text']
        else:
            arduino_status = "[ARDUINO] Arduino: DESCONECTADO"
            signal_color = (128, 128, 128)
            arduino_text = "Solo detecci√≥n visual"
            behavior_text = ""
        
        cv2.putText(dual_view, status_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(dual_view, status_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)
        
        cv2.putText(dual_view, stats_text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(dual_view, stats_text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
        
        cv2.putText(dual_view, camera_text, (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(dual_view, camera_text, (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
        
        cv2.putText(dual_view, arduino_status, (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.5, signal_color, 2)
        cv2.putText(dual_view, arduino_text, (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.4, signal_color, 2)
        if behavior_text:
            cv2.putText(dual_view, behavior_text, (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.35, signal_color, 1)
        
        # Mostrar vista dual
        cv2.imshow('[CHESTNUT] Vista Dual: Normal + Filtros √ìpticos Avanzados', dual_view)
        
        # Manejar teclas
        key = cv2.waitKey(1) & 0xFF
        if key == 27:  # ESC
            break
        elif key == ord('c'):
            # Cambiar confianza
            try:
                new_conf = float(input(f"\nNueva confianza (actual: {confidence:.2f}): "))
                if 0.1 <= new_conf <= 1.0:
                    confidence = new_conf
                    success(f"Confianza actualizada: {confidence:.2f}")
                else:
                    error("Confianza debe estar entre 0.1 y 1.0")
            except (ValueError, EOFError, KeyboardInterrupt):
                error("Valor inv√°lido o entrada cancelada")
        elif key == ord('s'):
            # Guardar captura dual
            filename = f"captura_dual_{frame_count}.jpg"
            cv2.imwrite(filename, dual_view)
            success(f"Captura dual guardada: {filename}")
        elif key == ord('i'):
            # Mostrar informaci√≥n
            info(f"\nInformaci√≥n actual:")
            info(f"   - Frame actual: {frame_count}")
            info(f"   - Confianza: {confidence:.2f}")
            info(f"   - Casta√±as SANAS detectadas: {total_sanas}")
            info(f"   - Casta√±as CONTAMINADAS detectadas: {total_contaminadas}")
            info(f"   - Frames con casta√±as: {frames_con_castanas}")
            info(f"   - C√°mara actual: {camera_id}")
            info(f"   - Clases detectadas: sports ball, apple, orange, donut, bowl")
            info(f"   - IDs YOLO: 32, 47, 49, 54, 45")
            info(f"   - Filtro actual: {current_filter.upper()}")
            info(f"   - Clasificaci√≥n Dual RGB + {current_filter.upper()}:")
            info(f"     ‚Ä¢ Verde (Sana): an√°lisis HSV + textura + filtro favorable")
            info(f"     ‚Ä¢ Rojo (Contaminada): grietas, moho, hongos detectados")
            info(f"   - Factores analizados:")
            info(f"     ‚Ä¢ RGB: Brillo (V), Saturaci√≥n (S), Variaci√≥n, Bordes")
            info(f"     ‚Ä¢ NUEVO: Fluorescencia verde ne√≥n (metabolitos f√∫ngicos)")
            info(f"     ‚Ä¢ Umbral fluorescencia: >5% p√≠xeles = CONTAMINADA")
            if current_filter == "crack":
                info(f"     ‚Ä¢ Grietas: Polarizaci√≥n √≥ptica, Hough lines, an√°lisis de sombras")
            elif current_filter == "mold":
                info(f"     ‚Ä¢ Moho: Manchas oscuras, colores verdes/azules, morfolog√≠a")
            elif current_filter == "fungal":
                info(f"     ‚Ä¢ Hongos: C√≠rculos (esporas), redes (micelio), patrones")
            elif current_filter == "mold_texture":
                info(f"     ‚Ä¢ Textura Moho: Granular (Penicillium), Fibroso (Aspergillus), Algodonoso (Fusarium)")
            elif current_filter == "spore_detection":
                info(f"     ‚Ä¢ Esporas: Detecci√≥n de c√≠rculos peque√±os, agrupaciones, an√°lisis de forma")
            elif current_filter == "uv_fluorescence":
                info(f"     ‚Ä¢ UV-A Fluorescencia: Simulaci√≥n ~365nm, filtro paso de banda BP470-505nm")
                info(f"       - Detecta fluorescencia de metabolitos f√∫ngicos (verde brillante)")
                info(f"       - NUEVO: Detecci√≥n autom√°tica de fluorescencia verde ne√≥n")
                info(f"       - Umbral: >5% p√≠xeles con fluorescencia = CONTAMINADA")
            elif current_filter == "nir_enhanced":
                info(f"     ‚Ä¢ NIR Mejorado: Simulaci√≥n 700-1100nm, absorci√≥n diferencial")
                info(f"       - Detecta humedad y variaciones internas no visibles")
            elif current_filter == "pipeline":
                info(f"     ‚Ä¢ Pipeline √ìptico Avanzado: Filtros especializados combinados")
                info(f"       - Grietas ‚Üí UV-A ‚Üí NIR ‚Üí Textura ‚Üí Hongos ‚Üí Esporas")
                info(f"       - Score total con tecnolog√≠a √≥ptica avanzada")
            else:
                info(f"     ‚Ä¢ An√°lisis est√°ndar: Detecci√≥n general")
        elif key == ord('m'):
            # Cambiar c√°mara
            info(f"\nC√°maras disponibles: {available_cameras}")
            info(f"   C√°mara actual: {camera_id}")
            try:
                new_camera = input(f"Selecciona una nueva c√°mara ({available_cameras[0]}-{available_cameras[-1]}): ").strip()
                if new_camera != "":
                    new_camera_id = int(new_camera)
                    if new_camera_id == camera_id:
                        warning(f"Ya est√°s usando la c√°mara {camera_id}")
                    else:
                        camera_id, camera_live = switch_camera(new_camera_id, available_cameras, camera_id, camera_live)
            except (ValueError, EOFError, KeyboardInterrupt):
                error("Entrada inv√°lida o cancelada")
        elif key == ord('f'):
            # Cambiar filtro usando configuraci√≥n
            info(f"\nüî¨ Filtros disponibles:")
            
            # Obtener filtros por categor√≠a desde configuraci√≥n
            categories = filter_manager.get_filters_by_category()
            favorite_filters = filter_manager.get_favorite_filters()
            
            filter_counter = 1
            filter_mapping = {}
                
            # Mostrar filtros por categor√≠a
            category_names = {
                "b√°sico": "FILTROS B√ÅSICOS",
                "hongos": "FILTROS PARA HONGOS", 
                "avanzado": "FILTROS AVANZADOS PARA CASTA√ëAS BRASILE√ëAS",
                "especializado": "FILTROS ESPECIALIZADOS",
                "pipeline": "PIPELINE AUTOMATIZADO"
            }
            
            for category, filters in categories.items():
                if filters:  # Solo mostrar categor√≠as con filtros
                    category_display = category_names.get(category, category.upper())
                    info(f"   === {category_display} ===")
                    
                    for filter_info_item in filters:
                        favorite_marker = " (FAVORITA)" if filter_info_item["is_favorite"] else ""
                        info(f"   {filter_counter}. {filter_info_item['name']}{favorite_marker} - {filter_info_item['description']}")
                        filter_mapping[str(filter_counter)] = filter_info_item["type"]
                        filter_counter += 1
                    print()
            
            info(f"   Filtro actual: {current_filter.upper()}")
            if favorite_filters:
                info(f"   Filtros favoritos: {', '.join(favorite_filters)}")
            try:
                filter_choice = input(f"Selecciona filtro (1-{filter_counter-1}): ").strip()
                
                # Usar mapeo din√°mico para seleccionar filtro
                if filter_choice in filter_mapping:
                    selected_filter = filter_mapping[filter_choice]
                    current_filter = selected_filter
                    
                    # Obtener informaci√≥n del filtro desde configuraci√≥n
                    filter_info_item = filter_manager.get_filter_info_from_config(selected_filter)
                    filter_name = filter_info_item["name"]
                    filter_desc = filter_info_item.get("description", "")
                    
                    success(f"Cambiado a filtro {filter_name} {filter_desc}")
                    
                    # Mostrar informaci√≥n adicional si es pipeline
                    if selected_filter == "pipeline":
                        info("El pipeline combina autom√°ticamente filtros de grietas y hongos")
                        info("An√°lisis completo: grietas ‚Üí textura moho ‚Üí hongos ‚Üí esporas")
                    
                else:
                    error("Opci√≥n inv√°lida")
            except (ValueError, EOFError, KeyboardInterrupt):
                error("Entrada inv√°lida o cancelada")
        elif key == ord('F'):
            # Mostrar informaci√≥n de filtros favoritos
            info(f"\nFiltros favoritos configurados:")
            favorite_filters = filter_manager.get_favorite_filters()
            
            if favorite_filters:
                for filter_type in favorite_filters:
                    filter_info_item = filter_manager.get_filter_info_from_config(filter_type)
                    category = filter_info_item.get("category", "desconocido")
                    recommended = filter_info_item.get("recommended_for", "")
                    info(f"   ‚Ä¢ {filter_info_item['name']} ({filter_type})")
                    info(f"     Categor√≠a: {category}")
                    if recommended:
                        info(f"     Recomendado para: {recommended}")
                    print()
                
                info(f"Filtro por defecto: {filter_manager.default_filter}")
                info(f"Para cambiar favoritos, edita filter_config.json")
            else:
                info("   No hay filtros marcados como favoritos")
                info(f"   Filtro por defecto: {filter_manager.default_filter}")
        elif key == ord('o'):
            # Optimizaci√≥n manual
            info(f"\nOptimizaci√≥n manual:")
            info(f"   - Frame actual: {frame_count}")
            info(f"   - FPS actual: {current_fps:.1f}")
            info(f"   - Tiempo promedio procesamiento: {avg_processing_time:.3f}s")
            info(f"   - Intervalo de salto: {frame_skip_interval}")
            info(f"   - Memoria GPU/CPU: Limpiando...")
            
            # Limpieza forzada de memoria
            import gc
            gc.collect()
            if device == "cuda":
                import torch
                torch.cuda.empty_cache()
            
            # Resetear contadores de rendimiento
            processing_times.clear()
            frame_skip_interval = 2  # Resetear a valor por defecto
            
            success(f"   ‚úÖ Memoria limpiada y contadores reseteados")
        
        # Teclas r√°pidas para filtros (desde configuraci√≥n)
        else:
            # Verificar si es una tecla r√°pida de filtro
            quick_key = chr(key)
            filter_type = filter_manager.get_filter_by_quick_key(quick_key)
            
            if filter_type:
                current_filter = filter_type
                filter_info = filter_manager.get_filter_info_from_config(filter_type)
                filter_name = filter_info["name"]
                success(f"Filtro cambiado a: {filter_name}")
    
    # Limpiar recursos
    camera_live.release()
    cv2.destroyAllWindows()
    if arduino_manager:
        arduino_manager.disconnect()
    
    info(f"\nEstad√≠sticas finales:")
    info(f"   - Frames procesados: {frame_count}")
    info(f"   - Frames con casta√±as: {frames_con_castanas}")
    info(f"   - Total casta√±as SANAS: {total_sanas}")
    info(f"   - Total casta√±as CONTAMINADAS: {total_contaminadas}")
    info(f"   - Total casta√±as detectadas: {total_sanas + total_contaminadas}")
    if (total_sanas + total_contaminadas) > 0:
        info(f"   - Porcentaje de casta√±as sanas: {(total_sanas/(total_sanas + total_contaminadas)*100):.1f}%")
        info(f"   - Porcentaje de casta√±as contaminadas: {(total_contaminadas/(total_sanas + total_contaminadas)*100):.1f}%")
    info(f"   - Porcentaje de frames con detecci√≥n: {(frames_con_castanas/frame_count*100):.1f}%")
    success("Detecci√≥n de casta√±as completada")

if __name__ == "__main__":
    main_func()

