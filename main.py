import cv2
from ultralytics import YOLO
import os
import json
import numpy as np
from typing import Optional, Dict, Any, Tuple, Union
import time
from image import FilterManager
from arduino import ArduinoManager

# Variables globales para Arduino
arduino_manager = None

# Variable global para dispositivo de procesamiento
device = "cpu"  # Por defecto CPU

def init_arduino_manager():
    """Inicializar el gestor de Arduino"""
    global arduino_manager
    arduino_manager = ArduinoManager()
    return arduino_manager

def load_camera_config() -> Optional[Dict[str, Any]]:
    """Cargar configuraci√≥n de c√°maras desde JSON"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(script_dir, "camera_config.json")
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        return config
    except FileNotFoundError:
        print("[WARNING] Archivo camera_config.json no encontrado. Usando configuraci√≥n por defecto.")
        return None
    except json.JSONDecodeError:
        print("[ERROR] Error al leer camera_config.json. Usando configuraci√≥n por defecto.")
        return None

def get_camera_name(cam_id: int, config: Optional[Dict[str, Any]]) -> str:
    """Obtener nombre personalizado de la c√°mara"""
    if config and "cameras" in config and str(cam_id) in config["cameras"]:
        return config["cameras"][str(cam_id)]["name"]
    return f"Dispositivo {cam_id}"

def get_camera_description(cam_id: int, config: Optional[Dict[str, Any]]) -> str:
    """Obtener descripci√≥n de la c√°mara"""
    if config and "cameras" in config and str(cam_id) in config["cameras"]:
        return config["cameras"][str(cam_id)].get("description", "")
    return ""

def is_favorite_camera(cam_id: int, config: Optional[Dict[str, Any]]) -> bool:
    """Verificar si la c√°mara es favorita"""
    if config and "cameras" in config and str(cam_id) in config["cameras"]:
        return config["cameras"][str(cam_id)].get("is_favorite", False)
    return False

def get_favorite_camera(config: Optional[Dict[str, Any]]) -> Optional[int]:
    """Obtener la c√°mara favorita"""
    if config and "cameras" in config:
        for cam_id, cam_info in config["cameras"].items():
            if cam_info.get("is_favorite", False):
                return int(cam_id)
    return None

def assign_color(chestnut_type: str) -> Tuple[int, int, int]:
    """Asignar colores espec√≠ficos para casta√±as"""
    color_map = {
        'sana': (0, 255, 0),        # Verde - Casta√±a sana
        'contaminada': (0, 0, 255),  # Rojo - Casta√±a contaminada
        'casta√±a': (255, 165, 0),    # Naranja - Casta√±a general
    }
    return color_map.get(chestnut_type, (255, 255, 255))  # Blanco por defecto

# Funciones de filtros movidas a image/filters.py

def analyze_chestnut_quality(crop_img: Optional[np.ndarray]) -> str:
    """Analizar calidad de casta√±a usando an√°lisis HSV y textura"""
    if crop_img is None or crop_img.size == 0:
        return 'sana'  # Por defecto si no se puede analizar
    
    # Convertir a HSV para an√°lisis de color
    hsv = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)
    _, s, v = cv2.split(hsv)  # Usar _ para variable no usada
    
    # Calcular estad√≠sticas de color
    mean_s = np.mean(s)
    mean_v = np.mean(v)
    std_v = np.std(v)  # Desviaci√≥n est√°ndar del brillo
    
    # An√°lisis de textura simple (detecci√≥n de bordes)
    gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])
    
    # Heur√≠stica para clasificar (ajustable seg√∫n tus im√°genes)
    # Casta√±as contaminadas suelen tener:
    # - Menor brillo (valores V bajos)
    # - Menor saturaci√≥n (colores m√°s gris√°ceos)
    # - M√°s bordes (manchas, moho, irregularidades)
    
    contamination_score = 0
    
    # Factor 1: Brillo bajo (posible moho o manchas oscuras)
    if mean_v < 70:
        contamination_score += 2
    elif mean_v < 100:
        contamination_score += 1
    
    # Factor 2: Saturaci√≥n baja (colores apagados)
    if mean_s < 40:
        contamination_score += 2
    elif mean_s < 60:
        contamination_score += 1
    
    # Factor 3: Mucha variaci√≥n en brillo (manchas)
    if std_v > 35:
        contamination_score += 1
    
    # Factor 4: Alta densidad de bordes (textura irregular)
    if edge_density > 0.15:
        contamination_score += 1
    
    # Clasificar basado en puntuaci√≥n
    return 'contaminada' if contamination_score >= 1 else 'sana'

def analyze_chestnut_quality_dual(crop_img: Optional[np.ndarray], filter_manager: FilterManager = None) -> str:
    """An√°lisis dual: RGB normal + simulaci√≥n UV para m√°xima precisi√≥n"""
    if crop_img is None or crop_img.size == 0:
        return 'sana'
    
    # An√°lisis RGB normal
    rgb_result = analyze_chestnut_quality(crop_img)
    
    # An√°lisis con simulaci√≥n UV usando FilterManager
    if filter_manager:
        uv_img, _, _ = filter_manager.apply_filter(crop_img, "uv")
        uv_result = analyze_chestnut_quality(uv_img)
    else:
        # Fallback si no hay FilterManager
        uv_result = rgb_result
    
    # L√≥gica de decisi√≥n dual
    final_result = 'contaminada' if (rgb_result == 'contaminada' or uv_result == 'contaminada') else 'sana'
    
    return final_result

def classify_chestnut(label: str, confidence: float, crop_img: Optional[np.ndarray] = None, filter_manager: FilterManager = None) -> Optional[str]:
    """Clasificar casta√±as en sanas o contaminadas usando YOLO + an√°lisis RGB"""
    label_lower = label.lower()
    
    # Clases que detectan casta√±as (similares por forma) - Actualizado con an√°lisis YOLO12n
    chestnut_classes = ['sports ball', 'apple', 'orange', 'donut', 'bowl']
    
    # Verificar si es una clase que puede ser casta√±a
    if label_lower not in chestnut_classes:
        return None  # No es una casta√±a
    
    # Si tenemos la imagen recortada, usar an√°lisis dual RGB + UV
    if crop_img is not None:
        return analyze_chestnut_quality_dual(crop_img, filter_manager)
    
    # Configuraci√≥n de clasificaci√≥n por clase y confianza
    classification_rules = {
        'sports ball': {'sana': 0.6, 'contaminada': 0.4},
        'apple': {'sana': 0.7, 'contaminada': 0.5},
        'orange': {'sana': 0.4, 'contaminada': 0.6},
        'donut': {'sana': 0.8, 'contaminada': 0.6},
        'bowl': {'sana': 0.8, 'contaminada': 0.6}
    }
    
    # Aplicar reglas de clasificaci√≥n
    rules = classification_rules.get(label_lower, {})
    if not rules:
        return None
    
    if confidence >= rules.get('sana', 0):
        return 'sana'
    elif confidence >= rules.get('contaminada', 0):
        return 'contaminada'
    
    return None  # No clasificar si confianza muy baja

def switch_camera(new_camera_id: int, available_cameras: list, current_camera_id: int, camera_live) -> Tuple[int, Any]:
    """Cambiar a una nueva c√°mara"""
    if new_camera_id in available_cameras and new_camera_id != current_camera_id:
        # Cerrar c√°mara actual
        camera_live.release()
        
        # Abrir nueva c√°mara
        new_camera = cv2.VideoCapture(new_camera_id)
        if new_camera.isOpened():
            new_camera.set(3, 1280)  # Ancho
            new_camera.set(4, 720)   # Alto
            print(f"[OK] Cambiado a c√°mara {new_camera_id}")
            return new_camera_id, new_camera
        else:
            print(f"[ERROR] No se pudo abrir c√°mara {new_camera_id}")
            # Restaurar c√°mara anterior
            old_camera = cv2.VideoCapture(current_camera_id)
            old_camera.set(3, 1280)
            old_camera.set(4, 720)
            return current_camera_id, old_camera
    else:
        print(f"[ERROR] C√°mara {new_camera_id} no disponible o ya seleccionada")
        return current_camera_id, camera_live

def create_dual_view(normal_img: np.ndarray, model: YOLO, conf: float = 0.5, filter_type: str = "nir", filter_manager: FilterManager = None) -> Tuple[np.ndarray, int, int, int]:
    """Crear vista dual: c√°mara normal + filtro especializado con detecciones"""
    # Usar FilterManager (requerido)
    if filter_manager:
        # Manejar pipeline especial
        if filter_type == "pipeline":
            filtered_processed, contamination_scores, pipeline_desc = filter_manager.apply_fungal_contamination_pipeline(normal_img.copy())
            filter_name = "PIPELINE COMPLETO"
            filter_desc = f"Score: {contamination_scores.get('total', 0.0):.2f}"
            
            # Mostrar reporte detallado cada 60 frames
            if hasattr(create_dual_view, 'frame_count'):
                create_dual_view.frame_count += 1
            else:
                create_dual_view.frame_count = 1
                
            if create_dual_view.frame_count % 60 == 0:  # Cada 2 segundos aprox
                print("\n" + pipeline_desc)
        else:
            filtered_processed, filter_name, filter_desc = filter_manager.apply_filter(normal_img.copy(), filter_type)
    else:
        # Error si no hay FilterManager
        print("[ERROR] FilterManager es requerido para create_dual_view")
        return normal_img, 0, 0, 0
    
    # ‚ö° OPTIMIZACI√ìN CR√çTICA: Solo una predicci√≥n YOLO (mejora 2x velocidad)
    # Usar solo la imagen normal para detecci√≥n, aplicar filtro solo para visualizaci√≥n
    normal_result = model.predict(normal_img, conf=conf, verbose=False, device=device)
    # filtered_result = model.predict(filtered_processed, conf=conf, verbose=False, device=device if 'device' in globals() else 'cpu')  # ELIMINADO
    
    # Dibujar detecciones en imagen normal
    normal_with_detections = normal_img.copy()
    filtered_with_detections = filtered_processed.copy()
    
    total_castanas = 0
    sana_count = 0
    contaminada_count = 0
    
    # Procesar detecciones en imagen normal
    for result in normal_result:
        if result.boxes is not None:
            for box in result.boxes:
                label = f"{result.names[int(box.cls[0])]}"
                score = box.conf.item()
                
                # Recortar la regi√≥n detectada para an√°lisis dual
                x1, y1, x2, y2 = int(box.xyxy[0][0]), int(box.xyxy[0][1]), int(box.xyxy[0][2]), int(box.xyxy[0][3])
                
                # Asegurar que las coordenadas est√°n dentro de la imagen
                x1 = max(0, x1)
                y1 = max(0, y1)
                x2 = min(normal_img.shape[1], x2)
                y2 = min(normal_img.shape[0], y2)
                
                if x2 > x1 and y2 > y1:
                    # Recortar imagen de la casta√±a para an√°lisis dual
                    crop_img = normal_img[y1:y2, x1:x2]
                    
                    # Clasificar casta√±a usando an√°lisis dual
                    chestnut_type = classify_chestnut(label, score, crop_img, filter_manager)
                    
                    if chestnut_type is not None:
                        total_castanas += 1
                        if chestnut_type == 'sana':
                            sana_count += 1
                        elif chestnut_type == 'contaminada':
                            contaminada_count += 1
                        
                        color = assign_color(chestnut_type)
                        
                        # Dibujar en imagen normal
                        cv2.rectangle(normal_with_detections, (x1, y1), (x2, y2), color, 2)
                        label_text = f"{chestnut_type.upper()}: {score:.2f}"
                        cv2.putText(normal_with_detections, label_text, (x1, y1-10), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
                        
                        # Dibujar en imagen filtrada (mismo rect√°ngulo, sin clasificaci√≥n adicional)
                        cv2.rectangle(filtered_with_detections, (x1, y1), (x2, y2), color, 2)
                        cv2.putText(filtered_with_detections, label_text, (x1, y1-10), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
    
    # Enviar se√±al al Arduino basada en el estado general del frame
    if arduino_manager and arduino_manager.enabled:
        arduino_manager.send_detection_signals(total_castanas, contaminada_count)
    
    # Crear vista dual lado a lado
    height, width = normal_with_detections.shape[:2]
    dual_view = np.zeros((height, width * 2, 3), dtype=np.uint8)
    
    # Colocar im√°genes lado a lado
    dual_view[:, :width] = normal_with_detections
    dual_view[:, width:] = filtered_with_detections
    
    # Agregar t√≠tulos con colores distintivos
    cv2.putText(dual_view, "CAMARA NORMAL", (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)  # Verde
    cv2.putText(dual_view, filter_name, (width + 10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 3)  # Magenta
    
    # Agregar subt√≠tulos explicativos
    cv2.putText(dual_view, "(RGB Natural)", (10, 60), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)
    cv2.putText(dual_view, filter_desc, (width + 10, 60), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)
    
    # L√≠nea divisoria
    cv2.line(dual_view, (width, 0), (width, height), (255, 255, 255), 2)
    
    return dual_view, total_castanas, sana_count, contaminada_count

def predict(model: YOLO, img: np.ndarray, conf: float = 0.5, filter_manager: FilterManager = None) -> Tuple[np.ndarray, Any, int, int, int]:
    """Realizar predicci√≥n y visualizar SOLO detecciones de casta√±as (sanas y contaminadas)"""
    
    sana_count = 0
    contaminada_count = 0
    total_castanas = 0
    
    # Realizar predicci√≥n
    results = model.predict(img, conf=conf)
    
    # Procesar resultados - SOLO casta√±as
    for result in results:
        if result.boxes is not None:
            for box in result.boxes:
                label = f"{result.names[int(box.cls[0])]}"
                score = box.conf.item()
                
                # Recortar la regi√≥n detectada para an√°lisis RGB
                x1, y1, x2, y2 = int(box.xyxy[0][0]), int(box.xyxy[0][1]), int(box.xyxy[0][2]), int(box.xyxy[0][3])
                
                # Asegurar que las coordenadas est√°n dentro de la imagen
                x1 = max(0, x1)
                y1 = max(0, y1)
                x2 = min(img.shape[1], x2)
                y2 = min(img.shape[0], y2)
                
                # Recortar imagen para an√°lisis
                crop_img = img[y1:y2, x1:x2] if y2 > y1 and x2 > x1 else None
                
                # Clasificar si es casta√±a y de qu√© tipo usando an√°lisis RGB
                chestnut_type = classify_chestnut(label, score, crop_img, filter_manager)
                
                if chestnut_type is not None:  # Solo procesar casta√±as
                    total_castanas += 1
                    
                    # Contar por tipo
                    if chestnut_type == 'sana':
                        sana_count += 1
                        emoji = "[OK]"
                    elif chestnut_type == 'contaminada':
                        contaminada_count += 1
                        emoji = "[ERROR]"
                    else:
                        emoji = "[CHESTNUT]"
                    
                    # Obtener color seg√∫n el tipo
                    color = assign_color(chestnut_type)
                    
                    # Dibujar rect√°ngulo (m√°s grueso para destacar)
                    cv2.rectangle(img, (x1, y1), (x2, y2), color=color, thickness=6)
                    
                    # Mostrar etiqueta con informaci√≥n
                    font = cv2.FONT_HERSHEY_SIMPLEX
                    label_text = f"{emoji} Casta√±a {chestnut_type} ({score:.2f})"
                    
                    cv2.putText(img, label_text, (x1, y1 - 10), font, 0.8, color=color, thickness=2)
    
    # Mostrar informaci√≥n SOLO de casta√±as en la imagen
    info_text = f"Casta√±as: {total_castanas} | Sanas: {sana_count} | Contaminadas: {contaminada_count}"
    cv2.putText(img, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    cv2.putText(img, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)
    
    return img, results, total_castanas, sana_count, contaminada_count

def main_func():
    """Funci√≥n principal para detecci√≥n de casta√±as sanas y contaminadas"""
    print("[CHESTNUT] Detector de Casta√±as - An√°lisis Dual RGB + UV Simulado + Arduino")
    print("=" * 70)
    print("[OK] Verde: Casta√±as SANAS (an√°lisis HSV + textura + simulaci√≥n UV)")
    print("[ERROR] Rojo: Casta√±as CONTAMINADAS (moho, manchas, fluorescencia detectada)")
    print("[AI] M√©todo: YOLO12n detecta ‚Üí An√°lisis dual RGB + UV simulado clasifica")
    print("[TIP] UV Simulado: Detecta fluorescencia de moho y contaminaci√≥n org√°nica")
    print("[ARDUINO] Arduino: Activa servo cuando detecta contaminaci√≥n")
    print("=" * 70)
    
    # Cargar configuraci√≥n de c√°maras
    camera_config = load_camera_config()
    
    # Inicializar sistema de filtros
    filter_manager = FilterManager()
    print(f"[FILTER] Sistema de filtros inicializado (GPU: {'[OK]' if filter_manager.cuda_available else '[ERROR]'})")
    
    # Cargar modelo YOLO12 preentrenado
    script_dir = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.join(script_dir, "core", "yolo12n.pt")
    
    print(f"[SEARCH] Cargando modelo YOLO12n: {model_path}")
    
    try:
        # Verificar disponibilidad de GPU
        import torch
        global device  # Declarar global al inicio
        print(f"[SEARCH] Verificando GPU...")
        print(f"   - PyTorch versi√≥n: {torch.__version__}")
        print(f"   - CUDA disponible: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"   - GPU detectada: {torch.cuda.get_device_name(0)}")
            print(f"   - Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
            device = "cuda"
            print("[FAST] Usando GPU para YOLO")
        else:
            print("[WARNING] GPU no disponible, usando CPU")
            device = "cpu"
        
        # Cargar modelo con dispositivo espec√≠fico
        model = YOLO(model_path)
        
        # Mover modelo a GPU si est√° disponible
        if torch.cuda.is_available():
            model.to(device)
            print("[OK] Modelo YOLO12n cargado en GPU exitosamente")
        else:
            print("[OK] Modelo YOLO12n cargado en CPU exitosamente")
            
    except Exception as e:
        print(f"[ERROR] Error cargando modelo YOLO12: {e}")
        print("üîÑ Intentando con modelo YOLOv8 como respaldo...")
        try:
            backup_path = os.path.join(script_dir, "core", "yolov8n.pt")
            model = YOLO(backup_path)
            
            # Mover modelo de respaldo a GPU si est√° disponible
            if torch.cuda.is_available():
                model.to(device)
                print("[OK] Modelo YOLOv8 de respaldo cargado en GPU exitosamente")
            else:
                print("[OK] Modelo YOLOv8 de respaldo cargado en CPU exitosamente")
        except Exception as e2:
            print(f"[ERROR] Error cargando modelo de respaldo: {e2}")
            return
    
    # Mostrar informaci√≥n del modelo
    print(f"üìä Informaci√≥n del modelo:")
    print(f"   - Dispositivo: {device.upper()}")
    print(f"   - Clases disponibles: {list(model.names.values())}")
    print(f"   - N√∫mero de clases: {len(model.names)}")
    
    # Mostrar rendimiento esperado
    if device == "cuda":
        print(f"[FAST] Rendimiento: GPU acelerado - Detecci√≥n ultra-r√°pida")
    else:
        print(f"[WARNING] Rendimiento: CPU - Detecci√≥n m√°s lenta")
    
    # Inicializar gestor de Arduino
    global arduino_manager
    arduino_manager = init_arduino_manager()
    
    # Configuraci√≥n interactiva de Arduino
    arduino_manager.interactive_setup()
    
    # Detectar c√°maras disponibles con informaci√≥n detallada
    available_cameras = []
    camera_info = {}
    
    print("[SEARCH] Detectando c√°maras disponibles...")
    
    for i in range(5):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            # Obtener informaci√≥n de la c√°mara
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            
            # Obtener nombre personalizado desde configuraci√≥n
            device_name = get_camera_name(i, camera_config)
            device_description = get_camera_description(i, camera_config)
            is_favorite = is_favorite_camera(i, camera_config)
            
            camera_info[i] = {
                'name': device_name,
                'description': device_description,
                'resolution': f"{width}x{height}",
                'fps': fps,
                'width': width,
                'height': height,
                'is_favorite': is_favorite
            }
            
            available_cameras.append(i)
            cap.release()
    
    if not available_cameras:
        print("[ERROR] No se encontraron c√°maras disponibles")
        return
    
    # Mostrar informaci√≥n detallada de las c√°maras
    print(f"\nüì∑ C√°maras disponibles ({len(available_cameras)} encontradas):")
    print("-" * 70)
    
    favorite_cam_id = None
    for cam_id in available_cameras:
        info = camera_info[cam_id]
        favorite_marker = " ‚≠ê FAVORITA" if info['is_favorite'] else ""
        print(f"   üìπ C√°mara {cam_id}: {info['name']}{favorite_marker}")
        
        if info['description']:
            print(f"      üìù {info['description']}")
        
        print(f"      üìê Resoluci√≥n: {info['resolution']} | FPS: {info['fps']:.1f}")
        
        if info['is_favorite']:
            favorite_cam_id = cam_id
        print()
    print("-" * 70)
    
    # Seleccionar c√°mara (siempre preguntar al usuario)
    camera_id = None
    
    while camera_id is None:
        try:
            print(f"\nüéØ Selecci√≥n de c√°mara:")
            print(f"   C√°maras disponibles: {available_cameras}")
            
            # Mostrar res√∫men r√°pido de cada c√°mara
            for cam_id in available_cameras:
                info = camera_info[cam_id]
                favorite_marker = " ‚≠ê" if info['is_favorite'] else ""
                print(f"   {cam_id}: {info['name']}{favorite_marker} - {info['resolution']} @ {info['fps']:.0f}fps")
            
            # Sugerir c√°mara favorita o por defecto
            default_cam = favorite_cam_id if favorite_cam_id else available_cameras[0]
            default_text = f"c√°mara favorita ({default_cam})" if favorite_cam_id else f"c√°mara {default_cam}"
            
            camera_choice = input(f"\nSelecciona una c√°mara ({available_cameras[0]}-{available_cameras[-1]}) o presiona Enter para usar la {default_text}: ").strip()
            
            if camera_choice == "":
                # Usar c√°mara favorita o por defecto
                camera_id = default_cam
                info = camera_info[camera_id]
                favorite_text = " (FAVORITA)" if info['is_favorite'] else ""
                print(f"[OK] Usando {default_text}: {info['name']} ({info['resolution']} @ {info['fps']:.0f}fps){favorite_text}")
            else:
                camera_id = int(camera_choice)
                if camera_id in available_cameras:
                    info = camera_info[camera_id]
                    favorite_text = " (FAVORITA)" if info['is_favorite'] else ""
                    print(f"[OK] C√°mara {camera_id} seleccionada: {info['name']} ({info['resolution']} @ {info['fps']:.0f}fps){favorite_text}")
                else:
                    print(f"[ERROR] C√°mara {camera_id} no disponible. Intenta con una de estas: {available_cameras}")
                    camera_id = None  # Reiniciar el bucle
                    
        except ValueError:
            print("[ERROR] Por favor ingresa un n√∫mero v√°lido")
            camera_id = None  # Reiniciar el bucle
        except (EOFError, KeyboardInterrupt):
            print("\n[WARNING] Selecci√≥n cancelada. Usando c√°mara favorita...")
            camera_id = default_cam
            info = camera_info[camera_id]
            favorite_text = " (FAVORITA)" if info['is_favorite'] else ""
            print(f"[OK] Usando c√°mara por defecto: {info['name']} ({info['resolution']} @ {info['fps']:.0f}fps){favorite_text}")
    
    camera_live = cv2.VideoCapture(camera_id)
    
    if not camera_live.isOpened():
        print(f"[ERROR] No se pudo abrir la c√°mara {camera_id}")
        return
    
    # Usar la resoluci√≥n nativa de la c√°mara seleccionada
    selected_info = camera_info[camera_id]
    native_width = selected_info['width']
    native_height = selected_info['height']
    native_fps = selected_info['fps']
    
    # Intentar configurar la resoluci√≥n nativa
    camera_live.set(cv2.CAP_PROP_FRAME_WIDTH, native_width)
    camera_live.set(cv2.CAP_PROP_FRAME_HEIGHT, native_height)
    camera_live.set(cv2.CAP_PROP_FPS, native_fps)
    
    # Verificar la resoluci√≥n configurada
    actual_width = int(camera_live.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_height = int(camera_live.get(cv2.CAP_PROP_FRAME_HEIGHT))
    actual_fps = camera_live.get(cv2.CAP_PROP_FPS)
    
    print(f"[OK] C√°mara configurada:")
    print(f"   üìπ Dispositivo: {selected_info['name']}")
    if selected_info['description']:
        print(f"   üìù Descripci√≥n: {selected_info['description']}")
    print(f"   üìê Resoluci√≥n: {actual_width}x{actual_height}")
    print(f"   üé¨ FPS: {actual_fps:.1f}")
    if selected_info['is_favorite']:
        print(f"   ‚≠ê Estado: C√ÅMARA FAVORITA")
    print("\nüìã Controles:")
    print("   - ESC: Salir")
    print("   - 'c': Cambiar confianza")
    print("   - 's': Guardar captura")
    print("   - 'i': Mostrar informaci√≥n del modelo")
    print("   - 'm': Cambiar c√°mara")
    print("   - 'f': Cambiar filtro (NIR/Spectral/Contraste/UV)")
    print("   - 'o': Optimizaci√≥n manual (limpiar memoria)")
    print("   - 'F': Mostrar informaci√≥n de filtros favoritos")
    
    frame_count = 0
    total_sanas = 0
    total_contaminadas = 0
    frames_con_castanas = 0
    confidence = 0.5
    current_filter = filter_manager.default_filter  # Filtro por defecto desde configuraci√≥n
    
    # Variables para medir rendimiento
    fps_counter = 0
    fps_start_time = time.time()
    current_fps = 0
    
    # Variables para optimizaci√≥n de memoria
    frame_skip_counter = 0
    frame_skip_interval = 2  # Procesar 1 de cada 2 frames para reducir carga
    memory_cleanup_interval = 300  # Limpiar memoria cada 300 frames (~10 segundos a 30fps)
    frame_count_memory = 0
    
    # Variables para control de carga del sistema
    processing_times = []
    max_processing_time = 0.05  # M√°ximo 50ms por frame (20 FPS m√≠nimo)
    
    while camera_live.isOpened():
        read, frame = camera_live.read()
        if not read:
            continue
        
        frame_count += 1
        fps_counter += 1
        frame_count_memory += 1
        frame_skip_counter += 1
        
        # Medir tiempo de procesamiento
        frame_start_time = time.time()
        
        # OPTIMIZACI√ìN 1: Saltar frames para reducir carga del sistema
        if frame_skip_counter < frame_skip_interval:
            # Mostrar frame anterior sin procesar
            if 'dual_view' in locals():
                cv2.imshow('[CHESTNUT] Vista Dual: Normal + UV Simulado', dual_view)
                key = cv2.waitKey(1) & 0xFF
                if key == 27:  # ESC
                    break
            continue
        
        frame_skip_counter = 0  # Resetear contador
        
        # OPTIMIZACI√ìN 2: Limpieza peri√≥dica de memoria
        if frame_count_memory >= memory_cleanup_interval:
            import gc
            gc.collect()  # Forzar garbage collection
            if device == "cuda":
                import torch
                torch.cuda.empty_cache()  # Limpiar cache de GPU
            frame_count_memory = 0
            print(f"[OPTIMIZACI√ìN] Memoria limpiada en frame {frame_count}")
        
        # Crear vista dual: c√°mara normal + filtro especializado
        dual_view, total_castanas, sanas, contaminadas = create_dual_view(frame, model, conf=confidence, filter_type=current_filter, filter_manager=filter_manager)
        
        # OPTIMIZACI√ìN 3: Medir tiempo de procesamiento y ajustar din√°micamente
        frame_processing_time = time.time() - frame_start_time
        processing_times.append(frame_processing_time)
        
        # Mantener solo los √∫ltimos 30 tiempos de procesamiento
        if len(processing_times) > 30:
            processing_times.pop(0)
        
        # Calcular tiempo promedio de procesamiento
        avg_processing_time = sum(processing_times) / len(processing_times) if processing_times else 0
        
        # Ajustar din√°micamente el intervalo de salto de frames si el sistema est√° sobrecargado
        if avg_processing_time > max_processing_time:
            frame_skip_interval = min(frame_skip_interval + 1, 4)  # M√°ximo salto de 3 frames
            if frame_count % 60 == 0:  # Cada 2 segundos aproximadamente
                print(f"[OPTIMIZACI√ìN] Sistema sobrecargado ({avg_processing_time:.3f}s), aumentando intervalo a {frame_skip_interval}")
        elif avg_processing_time < max_processing_time * 0.5 and frame_skip_interval > 1:
            frame_skip_interval = max(frame_skip_interval - 1, 1)  # Reducir intervalo si el sistema est√° bien
            if frame_count % 60 == 0:
                print(f"[OPTIMIZACI√ìN] Sistema estable ({avg_processing_time:.3f}s), reduciendo intervalo a {frame_skip_interval}")
        
        # Calcular FPS cada 30 frames
        if fps_counter >= 30:
            current_time = time.time()
            elapsed_time = current_time - fps_start_time
            current_fps = fps_counter / elapsed_time
            fps_counter = 0
            fps_start_time = current_time
        
        # Acumular estad√≠sticas
        total_sanas += sanas
        total_contaminadas += contaminadas
        if total_castanas > 0:
            frames_con_castanas += 1
        
        # Mostrar informaci√≥n adicional con FPS y rendimiento
        fps_text = f"FPS: {current_fps:.1f}" if current_fps > 0 else "FPS: Calculando..."
        processing_text = f"Proc: {avg_processing_time:.3f}s | Skip: {frame_skip_interval}"
        status_text = f"Frame: {frame_count} | {fps_text} | {processing_text} | Confianza: {confidence:.2f}"
        stats_text = f"Sanas: {total_sanas} | Contaminadas: {total_contaminadas}"
        camera_text = f"C√°mara: {camera_id} | Filtro: {current_filter.upper()} | Presiona 'f' para cambiar filtro"
        
        # Informaci√≥n de Arduino
        if arduino_manager and arduino_manager.enabled:
            status_info = arduino_manager.get_status_info()
            arduino_status = "[ARDUINO] Arduino: CONECTADO"
            signal_color = status_info['signal_color']
            arduino_text = f"√öltima se√±al: {status_info['last_signal']}" if status_info['last_signal'] else "Esperando detecci√≥n..."
            behavior_text = status_info['behavior_text']
        else:
            arduino_status = "[ARDUINO] Arduino: DESCONECTADO"
            signal_color = (128, 128, 128)
            arduino_text = "Solo detecci√≥n visual"
            behavior_text = ""
        
        cv2.putText(dual_view, status_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(dual_view, status_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)
        
        cv2.putText(dual_view, stats_text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(dual_view, stats_text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
        
        cv2.putText(dual_view, camera_text, (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(dual_view, camera_text, (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
        
        cv2.putText(dual_view, arduino_status, (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.5, signal_color, 2)
        cv2.putText(dual_view, arduino_text, (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.4, signal_color, 2)
        if behavior_text:
            cv2.putText(dual_view, behavior_text, (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.35, signal_color, 1)
        
        # Mostrar vista dual
        cv2.imshow('[CHESTNUT] Vista Dual: Normal + UV Simulado', dual_view)
        
        # Manejar teclas
        key = cv2.waitKey(1) & 0xFF
        if key == 27:  # ESC
            break
        elif key == ord('c'):
            # Cambiar confianza
            try:
                new_conf = float(input(f"\nNueva confianza (actual: {confidence:.2f}): "))
                if 0.1 <= new_conf <= 1.0:
                    confidence = new_conf
                    print(f"[OK] Confianza actualizada: {confidence:.2f}")
                else:
                    print("[ERROR] Confianza debe estar entre 0.1 y 1.0")
            except (ValueError, EOFError, KeyboardInterrupt):
                print("[ERROR] Valor inv√°lido o entrada cancelada")
        elif key == ord('s'):
            # Guardar captura dual
            filename = f"captura_dual_{frame_count}.jpg"
            cv2.imwrite(filename, dual_view)
            print(f"üíæ Captura dual guardada: {filename}")
        elif key == ord('i'):
            # Mostrar informaci√≥n
            print(f"\nüìä Informaci√≥n actual:")
            print(f"   - Frame actual: {frame_count}")
            print(f"   - Confianza: {confidence:.2f}")
            print(f"   - Casta√±as SANAS detectadas: {total_sanas}")
            print(f"   - Casta√±as CONTAMINADAS detectadas: {total_contaminadas}")
            print(f"   - Frames con casta√±as: {frames_con_castanas}")
            print(f"   - C√°mara actual: {camera_id}")
            print(f"   - Clases detectadas: sports ball, apple, orange, donut, bowl")
            print(f"   - IDs YOLO: 32, 47, 49, 54, 45")
            print(f"   - Filtro actual: {current_filter.upper()}")
            print(f"   - Clasificaci√≥n Dual RGB + {current_filter.upper()}:")
            print(f"     ‚Ä¢ Verde (Sana): an√°lisis HSV + textura + filtro favorable")
            print(f"     ‚Ä¢ Rojo (Contaminada): moho, manchas, contaminaci√≥n detectada")
            print(f"   - Factores analizados:")
            print(f"     ‚Ä¢ RGB: Brillo (V), Saturaci√≥n (S), Variaci√≥n, Bordes")
            if current_filter == "nir":
                print(f"     ‚Ä¢ NIR Avanzado: Haralick, Watershed, Sobel, Morfolog√≠a")
            elif current_filter == "spectral":
                print(f"     ‚Ä¢ Spectral: PCA, NDVI, Anomal√≠as espectrales")
            elif current_filter == "contrast":
                print(f"     ‚Ä¢ Textura: LBP, Gradientes, Patrones irregulares")
            elif current_filter == "mold":
                print(f"     ‚Ä¢ Moho: Manchas oscuras, colores verdes/azules, morfolog√≠a")
            elif current_filter == "rot":
                print(f"     ‚Ä¢ Podredumbre: Baja textura, amarronamiento, suavizaci√≥n")
            elif current_filter == "fungal":
                print(f"     ‚Ä¢ Hongos: C√≠rculos (esporas), redes (micelio), patrones")
            elif current_filter == "mycotoxin":
                print(f"     ‚Ä¢ Micotoxinas: Decoloraciones amarronadas/verdosas, texturas granulares")
            elif current_filter == "aflatoxin":
                print(f"     ‚Ä¢ Aflatoxinas: Fluorescencia azul-verde, patrones de red (Aspergillus)")
            elif current_filter == "discoloration":
                print(f"     ‚Ä¢ Decoloraci√≥n: An√°lisis multi-espectral, patrones de difusi√≥n")
            elif current_filter == "mold_texture":
                print(f"     ‚Ä¢ Textura Moho: Granular (Penicillium), Fibroso (Aspergillus), Algodonoso (Fusarium)")
            elif current_filter == "spore_detection":
                print(f"     ‚Ä¢ Esporas: Detecci√≥n de c√≠rculos peque√±os, agrupaciones, an√°lisis de forma")
            elif current_filter == "brazil_chestnut":
                print(f"     ‚Ä¢ Casta√±a Brasile√±a: Color marr√≥n-dorado, grietas en c√°scara, manchas espec√≠ficas")
            elif current_filter == "pipeline":
                print(f"     ‚Ä¢ Pipeline Completo: Combina 7 filtros relevantes para an√°lisis exhaustivo")
                print(f"       - Normalizaci√≥n ‚Üí Decoloraci√≥n ‚Üí Textura Moho ‚Üí Hongos ‚Üí Esporas ‚Üí Micotoxinas ‚Üí Aflatoxinas")
                print(f"       - Score total de contaminaci√≥n con recomendaciones autom√°ticas")
            else:
                print(f"     ‚Ä¢ UV: Fluorescencia, contraste mejorado")
        elif key == ord('m'):
            # Cambiar c√°mara
            print(f"\nüì∑ C√°maras disponibles: {available_cameras}")
            print(f"   C√°mara actual: {camera_id}")
            try:
                new_camera = input(f"Selecciona una nueva c√°mara ({available_cameras[0]}-{available_cameras[-1]}): ").strip()
                if new_camera != "":
                    new_camera_id = int(new_camera)
                    if new_camera_id == camera_id:
                        print(f"[WARNING] Ya est√°s usando la c√°mara {camera_id}")
                    else:
                        camera_id, camera_live = switch_camera(new_camera_id, available_cameras, camera_id, camera_live)
            except (ValueError, EOFError, KeyboardInterrupt):
                print("[ERROR] Entrada inv√°lida o cancelada")
        elif key == ord('f'):
            # Cambiar filtro usando configuraci√≥n
            print(f"\nüî¨ Filtros disponibles:")
            
            # Obtener filtros por categor√≠a desde configuraci√≥n
            categories = filter_manager.get_filters_by_category()
            favorite_filters = filter_manager.get_favorite_filters()
            
            filter_counter = 1
            filter_mapping = {}
            
            # Mostrar filtros por categor√≠a
            category_names = {
                "b√°sico": "FILTROS B√ÅSICOS",
                "hongos": "FILTROS PARA HONGOS", 
                "avanzado": "FILTROS AVANZADOS PARA CASTA√ëAS BRASILE√ëAS",
                "especializado": "FILTROS ESPECIALIZADOS",
                "pipeline": "PIPELINE AUTOMATIZADO"
            }
            
            for category, filters in categories.items():
                if filters:  # Solo mostrar categor√≠as con filtros
                    category_display = category_names.get(category, category.upper())
                    print(f"   === {category_display} ===")
                    
                    for filter_info in filters:
                        favorite_marker = " ‚≠ê" if filter_info["is_favorite"] else ""
                        print(f"   {filter_counter}. {filter_info['name']}{favorite_marker} - {filter_info['description']}")
                        filter_mapping[str(filter_counter)] = filter_info["type"]
                        filter_counter += 1
                    print()
            
            print(f"   Filtro actual: {current_filter.upper()}")
            if favorite_filters:
                print(f"   Filtros favoritos: {', '.join(favorite_filters)}")
            try:
                filter_choice = input(f"Selecciona filtro (1-{filter_counter-1}): ").strip()
                
                # Usar mapeo din√°mico para seleccionar filtro
                if filter_choice in filter_mapping:
                    selected_filter = filter_mapping[filter_choice]
                    current_filter = selected_filter
                    
                    # Obtener informaci√≥n del filtro desde configuraci√≥n
                    filter_info = filter_manager.get_filter_info_from_config(selected_filter)
                    filter_name = filter_info["name"]
                    filter_desc = filter_info.get("description", "")
                    
                    print(f"[OK] Cambiado a filtro {filter_name} {filter_desc}")
                    
                    # Mostrar informaci√≥n adicional si es pipeline
                    if selected_filter == "pipeline":
                        print("[INFO] El pipeline combina autom√°ticamente los 7 filtros m√°s relevantes")
                        print("[INFO] An√°lisis completo: normalizaci√≥n ‚Üí decoloraci√≥n ‚Üí textura moho ‚Üí hongos ‚Üí esporas ‚Üí micotoxinas ‚Üí aflatoxinas")
                    
                else:
                    print("[ERROR] Opci√≥n inv√°lida")
            except (ValueError, EOFError, KeyboardInterrupt):
                print("[ERROR] Entrada inv√°lida o cancelada")
        elif key == ord('F'):
            # Mostrar informaci√≥n de filtros favoritos
            print(f"\n‚≠ê Filtros favoritos configurados:")
            favorite_filters = filter_manager.get_favorite_filters()
            
            if favorite_filters:
                for filter_type in favorite_filters:
                    filter_info = filter_manager.get_filter_info_from_config(filter_type)
                    category = filter_info.get("category", "desconocido")
                    recommended = filter_info.get("recommended_for", "")
                    print(f"   ‚Ä¢ {filter_info['name']} ({filter_type})")
                    print(f"     Categor√≠a: {category}")
                    if recommended:
                        print(f"     Recomendado para: {recommended}")
                    print()
                
                print(f"üìã Filtro por defecto: {filter_manager.default_filter}")
                print(f"üí° Para cambiar favoritos, edita filter_config.json")
            else:
                print("   No hay filtros marcados como favoritos")
                print(f"   Filtro por defecto: {filter_manager.default_filter}")
        elif key == ord('o'):
            # Optimizaci√≥n manual
            print(f"\nüîß Optimizaci√≥n manual:")
            print(f"   - Frame actual: {frame_count}")
            print(f"   - FPS actual: {current_fps:.1f}")
            print(f"   - Tiempo promedio procesamiento: {avg_processing_time:.3f}s")
            print(f"   - Intervalo de salto: {frame_skip_interval}")
            print(f"   - Memoria GPU/CPU: Limpiando...")
            
            # Limpieza forzada de memoria
            import gc
            gc.collect()
            if device == "cuda":
                import torch
                torch.cuda.empty_cache()
            
            # Resetear contadores de rendimiento
            processing_times.clear()
            frame_skip_interval = 2  # Resetear a valor por defecto
            
            print(f"   ‚úÖ Memoria limpiada y contadores reseteados")
    
    # Limpiar recursos
    camera_live.release()
    cv2.destroyAllWindows()
    if arduino_manager:
        arduino_manager.disconnect()
    
    print(f"\nüìä Estad√≠sticas finales:")
    print(f"   - Frames procesados: {frame_count}")
    print(f"   - Frames con casta√±as: {frames_con_castanas}")
    print(f"   - Total casta√±as SANAS: {total_sanas}")
    print(f"   - Total casta√±as CONTAMINADAS: {total_contaminadas}")
    print(f"   - Total casta√±as detectadas: {total_sanas + total_contaminadas}")
    if (total_sanas + total_contaminadas) > 0:
        print(f"   - Porcentaje de casta√±as sanas: {(total_sanas/(total_sanas + total_contaminadas)*100):.1f}%")
        print(f"   - Porcentaje de casta√±as contaminadas: {(total_contaminadas/(total_sanas + total_contaminadas)*100):.1f}%")
    print(f"   - Porcentaje de frames con detecci√≥n: {(frames_con_castanas/frame_count*100):.1f}%")
    print("[OK] Detecci√≥n de casta√±as completada")

if __name__ == "__main__":
    main_func()

